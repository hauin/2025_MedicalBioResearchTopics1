{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, ToTensord\n",
    "from monai.networks.nets import Regressor\n",
    "from monai.utils import set_determinism, first\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics import Accuracy\n",
    "import shap\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import nilearn.image as nli\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transforms=None):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        data_transformed = self.transforms(self.data[idx]) if self.transforms else self.data[idx]\n",
    "        return data_transformed\n",
    "\n",
    "def load_data(data_path, modalities, additional_variables, batch_size, inference):\n",
    "    df = pd.read_csv(os.path.join(data_path, 'Subjects.csv'))\n",
    "    subjects = df['ID'].to_numpy()\n",
    "    data_dicts = []\n",
    "    for index, subject in enumerate(subjects):\n",
    "        subject_dict = {}\n",
    "        for modality in modalities:\n",
    "            subject_dict[modality] = os.path.join(data_path, modality, f\"{subject:03d}.nii.gz\")\n",
    "        if inference:\n",
    "            for variable in additional_variables:\n",
    "                if variable != 'Sex':\n",
    "                    subject_dict[variable] = df[variable].to_numpy()[index]\n",
    "        else:\n",
    "            for variable in additional_variables:\n",
    "                subject_dict[variable] = df[variable].to_numpy()[index]\n",
    "        data_dicts.append(subject_dict)\n",
    "    imtrans = Compose([\n",
    "        LoadImaged(keys=modalities, image_only=True),\n",
    "        EnsureChannelFirstd(keys=modalities),\n",
    "        ScaleIntensityd(keys=modalities, minv=0, maxv=1),\n",
    "        ToTensord(keys=modalities)])\n",
    "    ds = CustomDataset(data=data_dicts, transforms=imtrans)\n",
    "    if inference:\n",
    "        test_loader = DataLoader(ds, batch_size=batch_size, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "        return test_loader\n",
    "    else:\n",
    "        train_ds, val_ds = train_test_split(ds, test_size=0.2, random_state=42)\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "        val_loader = DataLoader(val_ds, batch_size=batch_size, num_workers=0, pin_memory=torch.cuda.is_available())\n",
    "        return train_loader, val_loader\n",
    "\n",
    "class CustomRegressor(nn.Module):\n",
    "    def __init__(self, input_channels=3, image_features=64, additional_features=1, out_features=2):\n",
    "        super(CustomRegressor, self).__init__()\n",
    "        self.image_regressor = Regressor(\n",
    "            in_shape=[input_channels, 79, 95, 79],\n",
    "            out_shape=image_features,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            kernel_size=3,\n",
    "            num_res_units=2)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(image_features + additional_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, out_features))\n",
    "    def forward(self, x, y):\n",
    "        x = self.image_regressor(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "def train_one_epoch(model, device, train_loader, modalities, additional_variables, optimizer, criterion, metric, scaler):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    metric.reset()\n",
    "    for batch_data in train_loader:\n",
    "        labels = batch_data['Sex'].to(device)\n",
    "        images = [batch_data[modality].to(device) for modality in modalities]\n",
    "        image_inputs = torch.cat(images, dim=1)\n",
    "        variables = [batch_data[variable].view(-1,1).to(device) for variable in additional_variables if variable != 'Sex']\n",
    "        variable_inputs = torch.cat(variables, dim=1)\n",
    "        current_batch_size = labels.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image_inputs, variable_inputs)\n",
    "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "            loss = criterion(outputs, labels)\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        metric(outputs[:, 1].reshape(current_batch_size, -1), labels.reshape(current_batch_size, -1))\n",
    "    epoch_metric = metric.compute().item()\n",
    "    return epoch_loss / len(train_loader), epoch_metric\n",
    "\n",
    "def validate_one_epoch(model, device, val_loader, modalities, additional_variables, metric):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    with torch.no_grad():\n",
    "        for batch_data in val_loader:\n",
    "            labels = batch_data['Sex'].to(device)\n",
    "            images = [batch_data[modality].to(device) for modality in modalities]\n",
    "            image_inputs = torch.cat(images, dim=1)\n",
    "            variables = [batch_data[variable].view(-1,1).to(device) for variable in additional_variables if variable != 'Sex']\n",
    "            variable_inputs = torch.cat(variables, dim=1)\n",
    "            if variable_inputs.dim() == 1:\n",
    "                variable_inputs = variable_inputs.unsqueeze(1)\n",
    "            current_batch_size = labels.size(0)\n",
    "            outputs = model(image_inputs, variable_inputs)\n",
    "            metric(outputs[:, 1].reshape(current_batch_size, -1), labels.reshape(current_batch_size, -1))\n",
    "    return metric.compute().item()\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=30, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "    def __call__(self, metric):\n",
    "        score = metric\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "def train_model(model_path, device, train_loader, val_loader, modalities, additional_variables, logger,\n",
    "    criterion=torch.nn.CrossEntropyLoss(), max_epochs=100, learning_rate=1e-4, weight_decay=1e-5, val_interval=1):\n",
    "    model = CustomRegressor(\n",
    "        input_channels=len(modalities),\n",
    "        image_features=64,\n",
    "        additional_features=1,\n",
    "        out_features=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "    metric = Accuracy(task='binary').to(device)\n",
    "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "    start_time = time.time()\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    early_stopping = EarlyStopping(patience=30, delta=0)\n",
    "    epoch_loss_values, epoch_metric_values, metric_values = [], [], []\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_loss, epoch_metric = train_one_epoch(model, device, train_loader, modalities, additional_variables, optimizer, criterion, metric, scaler)\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        epoch_metric_values.append(epoch_metric)\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            val_metric = validate_one_epoch(model, device, val_loader, modalities, additional_variables, metric)\n",
    "            metric_values.append(val_metric)\n",
    "            if val_metric > best_metric:\n",
    "                best_metric = val_metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(model_path, \"BestMetricModel.pth\"))\n",
    "                logger.info(f\"Best accuracy: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "            early_stopping(val_metric)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "        epoch_end_time = time.time()\n",
    "        logger.info(f\"Epoch {epoch + 1} computed for {(epoch_end_time - epoch_start_time)/60:.2f} mins - Training loss: {epoch_loss:.4f}, Training accuracy: {epoch_metric:.4f}, Validation accuracy: {val_metric:.4f}\")\n",
    "        lr_scheduler.step()\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    logger.info(f\"Best accuracy: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
    "    print(f\"Best accuracy: {best_metric:.3f} at epoch {best_metric_epoch}; Total time consumed: {total_time/60:.2f} mins\")\n",
    "    return model, epoch_loss_values, epoch_metric_values, metric_values\n",
    "\n",
    "def plot_metric_values(model_path, epoch_loss_values, epoch_metric_values, metric_values, val_interval=1):\n",
    "    _, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].plot( [i + 1 for i in range(len(epoch_loss_values))], epoch_loss_values, label='Training Loss', color='red')\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[1].plot([i + 1 for i in range(len(epoch_metric_values))], epoch_metric_values, label='Training MAE', color='red')\n",
    "    axs[1].plot([val_interval * (i + 1) for i in range(len(metric_values))], metric_values, label='Validation MAE', color='blue')\n",
    "    axs[1].set_title('Training accuracy vs. Validation accuracy')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(model_path, \"Performance.png\"), dpi=300)\n",
    "\n",
    "def apply_best_model(model_path, model, device, test_loader, modalities, additional_variables): \n",
    "    model.load_state_dict(torch.load(os.path.join(model_path, \"BestMetricModel.pth\")))\n",
    "    model.eval()\n",
    "    predictions = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            images = [batch_data[modality].to(device) for modality in modalities]\n",
    "            image_inputs = torch.cat(images, dim=1)\n",
    "            variables = [batch_data[variable].view(-1,1).to(device) for variable in additional_variables if variable != 'Sex']\n",
    "            variable_inputs = torch.cat(variables, dim=1)\n",
    "            if variable_inputs.dim() == 1:\n",
    "                variable_inputs = variable_inputs.unsqueeze(1)\n",
    "            outputs = model(image_inputs, variable_inputs).flatten()\n",
    "            predictions = np.append(predictions, outputs.cpu().numpy())\n",
    "    np.savetxt(os.path.join(model_path, \"Predictions.txt\"), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"train\"\n",
    "test_data_path = \"test\"\n",
    "model_path_prefix = \"Classifier\"\n",
    "modalities = [\"GM\", \"DMN\", \"FA\"]\n",
    "additional_variables = [\"Sex\", \"Age\"]\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "batch_size = 5\n",
    "max_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "val_interval = 1\n",
    "\n",
    "model_path = f\"{model_path_prefix}_BatchSize{batch_size}_MaxEpochs{max_epochs}_LearningRate{learning_rate:.0e}_WeightDecay{weight_decay:.0e}\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Device:', device)\n",
    "log_file = os.path.join(model_path, \"Prediction.log\")\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = load_data(train_data_path, modalities, additional_variables, batch_size, False)\n",
    "\n",
    "tr = first(train_loader)\n",
    "print('Data shape for training:')\n",
    "for key, value in tr.items():\n",
    "    print(f'{key}: {list(value.shape)} \\u00D7 {len(train_loader)}')\n",
    "vl = first(val_loader)\n",
    "print('\\nData shape for validation:')\n",
    "for key, value in vl.items():\n",
    "    print(f'{key}: {list(value.shape)} \\u00D7 {len(val_loader)}')\n",
    "\n",
    "_, axs = plt.subplots(1, len(modalities), figsize=(len(modalities) * 4, 5))\n",
    "for i, key in enumerate(modalities):\n",
    "    image = tr[key][0, 0, :, :, :]\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.numpy()\n",
    "    middle_index = image.shape[2] // 2\n",
    "    slice_2d = np.squeeze(image[:, :, middle_index])\n",
    "    ax = axs[i]\n",
    "    ax.imshow(np.rot90(slice_2d), cmap='gray')\n",
    "    ax.set_title(key)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, epoch_loss_values, epoch_metric_values, metric_values = train_model(model_path, device, train_loader, val_loader,\n",
    "    modalities, additional_variables, logger, criterion, max_epochs, learning_rate, weight_decay, val_interval)\n",
    "plot_metric_values(model_path, epoch_loss_values, epoch_metric_values, metric_values, val_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = load_data(test_data_path, modalities, additional_variables, batch_size, True)\n",
    "apply_best_model(model_path, model, device, test_loader, modalities, additional_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP (SHapley Additive exPlanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP GradientExplainer with training data\n",
    "\n",
    "# train_images_list = []\n",
    "# train_variables_list = []\n",
    "# for train_batch_data in train_loader:\n",
    "#     train_images = [train_batch_data[modality].to(device) for modality in modalities]\n",
    "#     train_image_inputs = torch.cat(train_images, dim=1)\n",
    "#     train_variables = [train_batch_data[variable].view(-1,1).to(device) for variable in additional_variables if variable != 'Sex']\n",
    "#     train_variable_inputs = torch.cat(train_variables, dim=1)\n",
    "#     train_images_list.append(train_image_inputs)\n",
    "#     train_variables_list.append(train_variable_inputs)\n",
    "# train_images_list = torch.cat(train_images_list, dim=0)\n",
    "# train_variables_list = torch.cat(train_variables_list, dim=0)\n",
    "# explainer = shap.GradientExplainer(model, [train_images_list, train_variables_list])\n",
    "\n",
    "train_batch_data = first(train_loader)\n",
    "train_images = [train_batch_data[modality].to(device) for modality in modalities]\n",
    "train_image_inputs = torch.cat(train_images, dim=1)\n",
    "train_variables = [train_batch_data[variable].view(-1,1).to(device) for variable in additional_variables if variable != 'Sex']\n",
    "train_variable_inputs = torch.cat(train_variables, dim=1)\n",
    "explainer = shap.GradientExplainer(model, [train_image_inputs, train_variable_inputs])\n",
    "\n",
    "# Compute SHAP values for validation data\n",
    "image_shap_values_list = []\n",
    "variable_shap_values_list = []\n",
    "val_images_list = []\n",
    "val_variables_list = []\n",
    "for val_batch_data in val_loader:\n",
    "    val_images = [val_batch_data[modality].to(device) for modality in modalities]\n",
    "    val_image_inputs = torch.cat(val_images, dim=1)\n",
    "    val_variables = [val_batch_data[variable].view(-1,1).to(device) for variable in additional_variables if variable != 'Sex']\n",
    "    val_variable_inputs = torch.cat(val_variables, dim=1)\n",
    "    shap_values = explainer.shap_values([val_image_inputs, val_variable_inputs])\n",
    "    image_shap_values_list.append(shap_values[0])\n",
    "    variable_shap_values_list.append(shap_values[1])\n",
    "    val_images_list.append(val_image_inputs.cpu().numpy())\n",
    "    val_variables_list.append(val_variable_inputs.cpu().numpy())\n",
    "image_shap_values_list = np.concatenate(image_shap_values_list, axis=0)\n",
    "variable_shap_values_list = np.concatenate(variable_shap_values_list, axis=0)\n",
    "val_images_list = np.concatenate(val_images_list, axis=0)\n",
    "val_variables_list = np.concatenate(val_variables_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot SHAP values for images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(len(modalities), 1, figsize=(12, len(modalities) * 4))\n",
    "for i, key in enumerate(modalities):\n",
    "    mean_abs_shap_values = np.mean(np.abs(image_shap_values_list[:, i, :, :, :, 1]), axis=0)\n",
    "    mean_images = np.mean(val_images_list[:, i, :, :, :], axis=0)\n",
    "    shap_values_img = nib.Nifti1Image(mean_abs_shap_values, np.eye(4))\n",
    "    thresholded_shap_values_img = nli.threshold_img(shap_values_img, threshold='95%', cluster_threshold=10)\n",
    "    map_img = nib.Nifti1Image(mean_images, np.eye(4))\n",
    "    plotting.plot_stat_map(thresholded_shap_values_img, bg_img=map_img, axes=axs[i], title=key, cmap=\"magma\", symmetric_cbar=False)\n",
    "    nib.save(shap_values_img, os.path.join(model_path, \"SHAPValues_\" + key + \".nii.gz\"))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot SHAP values for additional variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [variable for variable in additional_variables if variable != 'Sex']\n",
    "shap.summary_plot(variable_shap_values_list[:, :, 1], val_variables_list, feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
