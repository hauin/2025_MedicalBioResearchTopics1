{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'train'\n",
    "predictors_paths = {\n",
    "    'GM': os.path.join(train_data_path, 'GM.csv'),\n",
    "    'WM': os.path.join(train_data_path, 'WM.csv'),\n",
    "    'ReHo': os.path.join(train_data_path, 'ReHo.csv'),\n",
    "    'PCGcorr': os.path.join(train_data_path, 'PCGcorr.csv'),\n",
    "    'FA': os.path.join(train_data_path, 'FA.csv'),\n",
    "    'MD': os.path.join(train_data_path, 'MD.csv')\n",
    "}\n",
    "additional_variables_path = os.path.join(train_data_path, 'Subjects.csv')\n",
    "\n",
    "# Predictors\n",
    "modalities = ['GM', 'ReHo', 'MD']\n",
    "selected_modalities = {modality: predictors_paths[modality] for modality in modalities if modality in predictors_paths}\n",
    "def read_and_rename(modality, path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={label: f\"{label}_{modality}\" for label in df.columns if label != 'ID'})\n",
    "    return df\n",
    "dfs = [read_and_rename(modality, path) for modality, path in selected_modalities.items()]\n",
    "predictors_df = reduce(lambda left, right: pd.merge(left, right, on='ID'), dfs)\n",
    "\n",
    "# Response and confounding variables\n",
    "additional_variables = ['Memory', 'Age', 'Sex', 'EducationYear']\n",
    "df = pd.read_csv(additional_variables_path)\n",
    "selected_variables = [variable for variable in additional_variables if variable in df.columns]\n",
    "additional_variables_df = df[[\"ID\"] + selected_variables]\n",
    "\n",
    "# Merge predictors with response and confounding variables on 'ID'\n",
    "df = pd.merge(additional_variables_df, predictors_df, on='ID')\n",
    "\n",
    "# Prepare X and y\n",
    "X = df.drop(columns=['ID', 'Memory'])\n",
    "y = df['Memory']\n",
    "\n",
    "# Split into training and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Sample size for training: {X_train.shape[0]}')\n",
    "print(f'Sample size for test: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_method = 'Lasso' # 'Lasso' or 'MI'\n",
    "\n",
    "if feature_selection_method == 'Lasso':\n",
    "    # Lasso regression\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    lasso = LassoCV(cv=5, random_state=42).fit(X_train_scaled, y_train)\n",
    "    print(f'Regularization strength hyperparameter for Lasso: {lasso.alpha_:.3f}')\n",
    "    selector = SelectFromModel(lasso, prefit=True)\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "elif feature_selection_method == 'MI':\n",
    "    # Mutual information\n",
    "    selector = SelectPercentile(mutual_info_regression, percentile=50)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "selected_mask = selector.get_support()\n",
    "print(f\"Selected features by {feature_selection_method}: {selected_mask.sum()} out of {X_train.shape[1]} total features\")\n",
    "selected_features = X_train.columns[selected_mask]\n",
    "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "X_test_selected = pd.DataFrame(selector.transform(X_test), columns=selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_method = 'ET' # 'ET', 'RF' or 'XGB'\n",
    "\n",
    "# Hyperparameter grid for ExtraTreesRegressor\n",
    "param_grid_et = {\n",
    "    'n_estimators': [100, 200, 300, 400],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30, 40],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4, 7],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2', 0.2, 0.5, 0.8], # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [False] # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "# Hyperparameter grid for RandomForestRegressor\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30, 40],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "# Hyperparameter grid for XGBRegressor\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of gradient boosted trees (boosting rounds)\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage used to prevent overfitting\n",
    "    'max_depth': [3, 6, 9, 12],  # Maximum depth of each tree\n",
    "    'min_child_weight': [1, 5, 10],  # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'subsample': [0.5, 0.7, 1.0],  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 1.0],  # Subsample ratio of columns when constructing each tree\n",
    "    'reg_alpha': [0, 0.1, 1],  # L1 regularization term on weights\n",
    "    'reg_lambda': [1, 2, 5]  # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "if ml_method == 'ET':\n",
    "    regressor = ExtraTreesRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid_et, cv=5, scoring='neg_mean_absolute_error')\n",
    "elif ml_method == 'RF':\n",
    "    regressor = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid_rf, cv=5, scoring='neg_mean_absolute_error')\n",
    "elif ml_method == 'XGB':\n",
    "    regressor = XGBRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid_xgb, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best cross-validation score {-grid_search.best_score_:.3f} by {ml_method} for hyperparameters: ', best_params)\n",
    "\n",
    "if ml_method == 'ET':\n",
    "    regressor = ExtraTreesRegressor(**best_params)\n",
    "elif ml_method == 'RF':\n",
    "    regressor = RandomForestRegressor(**best_params)\n",
    "elif ml_method == 'XGB':\n",
    "    regressor = XGBRegressor(**best_params)\n",
    "regressor.fit(X_train_selected, y_train)\n",
    "predictions = regressor.predict(X_test_selected)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"MAE by {ml_method}: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = regressor.feature_importances_\n",
    "features_and_importances = zip(selected_features, feature_importances)\n",
    "sorted_features_and_importances = sorted(features_and_importances, key=lambda x: x[1], reverse=True)\n",
    "top_features_and_importances = sorted_features_and_importances[:9]\n",
    "print(f\"Top features' importances by {ml_method}:\")\n",
    "for no, feature_importance in enumerate(top_features_and_importances):\n",
    "    print(f\"{no + 1}. {feature_importance[0]}: {feature_importance[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP (SHapley Additive exPlanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(regressor)\n",
    "shap_values = explainer(X_test_selected)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X_test_selected, max_display=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'test'\n",
    "predictors_paths = {\n",
    "    'GM': os.path.join(test_data_path, 'GM.csv'),\n",
    "    'WM': os.path.join(test_data_path, 'WM.csv'),\n",
    "    'ReHo': os.path.join(test_data_path, 'ReHo.csv'),\n",
    "    'PCGcorr': os.path.join(test_data_path, 'PCGcorr.csv'),\n",
    "    'FA': os.path.join(test_data_path, 'FA.csv'),\n",
    "    'MD': os.path.join(test_data_path, 'MD.csv')\n",
    "}\n",
    "additional_variables_path = os.path.join(test_data_path, 'Subjects.csv')\n",
    "\n",
    "# Predictors\n",
    "selected_modalities = {modality: predictors_paths[modality] for modality in modalities if modality in predictors_paths}\n",
    "dfs = [read_and_rename(modality, path) for modality, path in selected_modalities.items()]\n",
    "predictors_df = reduce(lambda left, right: pd.merge(left, right, on='ID'), dfs)\n",
    "\n",
    "# Confounding variables\n",
    "df = pd.read_csv(additional_variables_path)\n",
    "selected_variables = [variable for variable in additional_variables if variable in df.columns]\n",
    "additional_variables_df = df[['ID'] + selected_variables]\n",
    "\n",
    "# Merge predictors with confounding variables on 'ID'\n",
    "df = pd.merge(additional_variables_df, predictors_df, on='ID')\n",
    "\n",
    "# Apply trained model\n",
    "X_ext = df.drop(columns=['ID'])\n",
    "X_ext_selected = pd.DataFrame(selector.transform(X_ext), columns=selected_features)\n",
    "predictions_ext = regressor.predict(X_ext_selected)\n",
    "\n",
    "# Save predictions\n",
    "np.savetxt(os.path.join(test_data_path, \"Predictions.txt\"), predictions_ext)\n",
    "\n",
    "# SHAP\n",
    "shap_values = explainer(X_ext_selected)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X_ext_selected, max_display=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
